E-Waste-Classification-Project/
Main directory containing the full AI-based e-waste classification system.

php
Copy
Edit
E-Waste-Classification-Project/
â”œâ”€â”€ ğŸ“ data/                         # Dataset folder (train/val/test images)
â”‚
â”œâ”€â”€ ğŸ“ models/                       # Trained model storage
â”‚   â””â”€â”€ efficientnetv2b0_e_waste.keras
â”‚
â”œâ”€â”€ ğŸ“ samples/                      # Sample images for VR-like webcam gestures
â”‚   â””â”€â”€ sample1.jpg, sample2.png, ...
â”‚
â”œâ”€â”€ ğŸ“ static/                       # Stores prediction logs and captured images
â”‚   â”œâ”€â”€ images/                     # Saved prediction images
â”‚   â””â”€â”€ predictions.csv             # Log file with timestamp, label, cost, recommendation
â”‚
â”œâ”€â”€ ğŸ“ utils/                        # Custom Python utility scripts
â”‚   â”œâ”€â”€ cost_estimator.py           # Returns estimated recycling cost per item
â”‚   â””â”€â”€ recommendation_engine.py    # Gives safe disposal and recycling tips
â”‚
â”œâ”€â”€ ğŸ“„ E-Waste Generation Classification.ipynb  # ğŸ“Œ Main notebook (all-in-one execution)
â”‚                                        â€¢ Model training with EfficientNetV2B0  
â”‚                                        â€¢ Gradio UI for prediction  
â”‚                                        â€¢ Cost estimation and recommendations  
â”‚                                        â€¢ Dashboard preview and logging  
â”‚
â”œâ”€â”€ ğŸ“„ captured.jpg                  # Sample captured image from webcam (IP/webcam)
â”œâ”€â”€ ğŸ“„ requirements.txt              # Dependencies (tensorflow, gradio, opencv, etc.)
â”‚
â”œâ”€â”€ ğŸ“ .gradio/                      # (Auto-created by Gradio)
â”œâ”€â”€ ğŸ“ .ipynb_checkpoints/           # (Jupyter autosave folder)
 Optional Notes for Report:
main notebook: Combine all features in one place (.ipynb)

upload_predict.py: Use for browser-based upload

webcam_predict.py: Use for live webcam image prediction

samples/: Used by VR-gesture script to classify based on hand signals

utils/: Makes code modular, reusable, and readable

static/predictions.csv: Used in dashboard tab to show prediction history
Notebook Contents (Sections)
1.  Library Installation and Imports
tensorflow, gradio, opencv-python-headless, matplotlib, seaborn, etc.

EfficientNetV2B0 used for model backbone.

2.  Data Loading and Preprocessing
Data organized under data/train, data/val, data/test.

Uses ImageDataGenerator for augmentation.

Batch size: 32 | Image size: 224x224

3.  EDA (Exploratory Data Analysis)
Shows sample images from training dataset.

Counts number of images per class using os and collections.Counter.

4.  Model Building (EfficientNetV2B0)
Loads base EfficientNetV2B0 without top layer.

Adds custom classification layers (GlobalAveragePooling2D, Dense).

Final layer: 10 classes with softmax.

5. ğŸ¯ Model Training
Uses EarlyStopping and ModelCheckpoint.

Loss: categorical_crossentropy

Optimizer: adam

Epochs: around 15â€“25 (assumed from later content)

6. âœ… Model Evaluation
Evaluates using classification_report and confusion_matrix.

Displays confusion matrix using ConfusionMatrixDisplay.

7.  Save Trained Model
Model saved to models/efficientnetv2b0_e_waste.keras.

8.  Gradio-Based Upload + Webcam Prediction
Interactive Gradio UI for:

Uploading an image

Capturing via webcam

Displays:

Predicted class

Estimated cost

Recycling recommendation

Prediction log saved in static/predictions.csv.

9. ğŸ“ˆ Prediction History Logging
Shows prediction history in tabular format using Pandas.

Option to clear logs using Gradio button.

10.  VR Gesture-Based Classifier (OpenCV + MediaPipe)
Uses webcam + MediaPipe to:

Switch sample images using âœ‹ (5 fingers)

Classify using ğŸ‘ (thumb up)

Displays result and recommendation live via OpenCV window.

11.  Final Summary
The notebook concludes with a prediction interface, logging, and full model deploymentâ€”all wrapped in one file for ease of demonstration and testing.
